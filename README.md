

# WOA-TOOL (EWOA Mammography Classifier)

End-to-end pipeline for training and serving a Mahalanobis-ratio classifier on mammogram radiomics using an **Enhanced Whale Optimization Algorithm (EWOA)** for feature selection. Includes:

* Feature extraction & preprocessing
* EWOA-driven feature selection + constrained τ selection
* Train/Validation/Test evaluation with specificity/recall trade-offs
* A clean CLI for preprocessing, training, predicting, and persisting τ
* A comparison script for **WOA vs EWOA** on single images

---

## 1) Quick Start

```bash
# 1) Create and activate a venv
python3 -m venv .venv
source .venv/bin/activate

# 1.2) Prepare Dataset
python3 prepare_metadata

# 2) Install requirements
pip install -r requirements.txt

# 3) Layout your data (see "Data Layout" below)

# 4) (Optional) Extract features & create processed arrays
python3 -m woa_tool.cli preprocess

# 5) Train + evaluate (balanced-speed mode)
FAST=2 python3 train_and_eval.py

# 6) Inspect the saved model
ls -lah models/model_ewoa.json

# 7) Predict on a new image
python3 -m woa_tool.cli predict \
  --model models/model_ewoa.json \
  --image data/test_images/1-002.jpg
```

---

## 2) Data Layout

```
repo-root/
├─ data/
│  ├─ raw/                     # (if you keep originals here)
│  ├─ test_images/             # sample images for prediction/testing
│  ├─ processed/               # generated by preprocess (X_train.npy, y_train.npy, etc.)
│  ├─ cache/
│  │  └─ features/             # per-image JSON feature cache (auto-created)
│  └─ test.csv                 # test metadata (see below)
├─ models/
│  └─ model_ewoa.json          # saved by train_and_eval.py
└─ woa_tool/
   ├─ __init__.py
   ├─ cli.py
   ├─ preprocess.py
   ├─ predict.py
   ├─ feature_extraction.py
   ├─ algorithms.py            # run_ewoa / run_woa
   └─ abnormality.py
```

### `data/test.csv` format

CSV with at least these columns:

* `patient_id` – any unique ID
* `Class` – {`B`,`M`} or {`0`,`1`} or {`benign`,`malignant`} (case-insensitive)
* `image_path` – absolute or relative path to the image file

Example:

```csv
patient_id,Class,image_path
1,B,data/test_images/1-001.jpg
2,M,data/test_images/1-002.jpg
```

---

## 3) Preprocessing (feature extraction → processed arrays)

You can let the **training script** build features on the fly from `data/test.csv`, but for speed and reproducibility it’s best to run preprocess and cache features to `data/processed`.

### Run

```bash
python3 -m woa_tool.cli preprocess
```

### What it does

* Walks your dataset, extracts radiomic features via `woa_tool.feature_extraction.extract_image_features`.
* Saves:

  * `data/processed/X_train.npy`, `y_train.npy` (and optional `X_test.npy`, `y_test.npy` if you’ve scripted that)
  * `data/cache/features/*.json` per-image feature cache (auto-used later)
* Ensures labels are binary. Training will enforce **0 = Benign**, **1 = Malignant** (flips if needed).

### Tips

* Preprocessing is idempotent; re-running will re-use cached features when possible.
* If you reorganize images, delete the cache folder to avoid stale paths:

  ```bash
  rm -rf data/cache/features
  ```

---

## 4) Training & Evaluation (the `train_and_eval.py` pipeline)

The main training pipeline lives in **`train_and_eval.py`**. It performs:

1. Load processed arrays (or build test features from `data/test.csv`)
2. Standardize features using train mean/std
3. EWOA feature selection (with OBL & adaptive `a(t)` strategy)
4. Bounded greedy + pairwise fine-tuning on the top Fisher-ranked features
5. Pooled covariance (Ledoit-Wolf shrinkage) with class means
6. **τ (tau) selection** under constraints (recall-leaning, with minimum specificity guardrails)
7. Save model → `models/model_ewoa.json`
8. Evaluate on TEST set at:

   * **Official τ** (saved from train/val)
   * **Constraint-picked τ** (e.g., Spec ≥ 0.40/0.45)

### FAST modes

Set `FAST` env to control runtime vs. thoroughness:

* `FAST=0` or unset → full (slowest, best)
* `FAST=1` → quick debug
* `FAST=2` → **balanced-speed** (recommended while iterating)

Example (balanced-speed):

```bash
FAST=2 python3 train_and_eval.py
```

You’ll see logs like:

* EWOA flips and pairwise swaps
* Chosen τ on train-val with SPEC/SENS
* Model saved path, features selected
* τ sweep on TEST (diagnostic)
* Official metrics at saved τ
* Constraint-picked operating point (e.g., Spec ≥ 0.40) and its metrics
* CSV artifacts:

  * `results_eval_pipeline.csv` (τ sweep)
  * `results_eval_summary.csv` (official + constrained points)

### What the model saves

`models/model_ewoa.json` schema (key subset):

```json
{
  "algo": "ewoa",
  "feature_names": [...],                // all features (ordered)
  "selected_idx": [ ... ],               // indices into feature_names
  "selected_names": [ ... ],             // convenience; same length as selected_idx
  "train_mu": [ ... ],                   // mean per feature (full vector)
  "train_sigma": [ ... ],                // std per feature (full vector)
  "class_labels": {"0":"Benign","1":"Malignant"},
  "class_stats": {
    "0": {"mu": [ ... ]},                // Benign mean (selected space)
    "1": {"mu": [ ... ]}                 // Malignant mean (selected space)
  },
  "Sp_inv": [ [...], ... ],              // pooled inverse covariance (selected space)
  "tau": 1.006,                          // official τ chosen on train/val
  "policy": {
    "sens_weight": 0.75,
    "min_sensitivity": 0.80,
    "min_specificity": 0.40,
    "fallback_spec_floor": 0.35,
    "lambda_spec": 1.0,
    "local_radius": 0.10,
    "taus": [0.50, 0.52, ... 1.70]
  },
  "cv_error": 0.4000,
  "cv_error_B": 0.4403,
  "cv_error_M": 0.3692
}
```

> Note: We **do not** store per-class σ in the model; the classifier uses `Sp_inv` (pooled inverse covariance) in the **selected** feature space.

### Choosing τ (threshold)

* The **decision rule** is: **Malignant if** `d_M ≤ τ * d_B` **else Benign**, where distances are **Mahalanobis** in the standardized, selected feature space.
* Training tries to satisfy feasible `(Sensitivity ≥ MIN_SENSITIVITY & Specificity ≥ MIN_SPECIFICITY)`; otherwise falls back to a guarded selection with `FALLBACK_SPEC_FLOOR`.
* You can **constrain test-time τ** to meet deployment policy (e.g., Spec ≥ 0.40/0.45). The script prints the best feasible point found in a dense τ grid.

---

## 5) Prediction

Use the CLI:

```bash
python3 -m woa_tool.cli predict \
  --model models/model_ewoa.json \
  --image data/test_images/1-002.jpg
```

Output JSON includes:

* `final_prediction` (`Benign`/`Malignant`)
* `distance_to_benign`, `distance_to_malignant`
* `tau` used
* Explanation strings and **abnormality inference** (calcifications/mass subtype when applicable)
* Z-scores for all features
* Top contributing features

### τ override (one-off)

```bash
python3 -m woa_tool.cli predict \
  --model models/model_ewoa.json \
  --image data/test_images/1-002.jpg \
  --tau-override 1.0014
```

You’ll see:

```
⚙️  τ override active → using τ = 1.0014
```

### Persist τ into the model (so every prediction uses it)

```bash
python3 -m woa_tool.cli set-tau --model models/model_ewoa.json --tau 1.0014
# Writes models/model_ewoa.json and a sidecar models/model_ewoa.json.tau
```

Now `predict` (no flags) will use `tau` from the JSON.

### Save predictions to a file

```bash
python3 -m woa_tool.cli predict \
  --model models/model_ewoa.json \
  --image data/test_images/1-002.jpg \
  --out-json out/pred_1-002.json
```

---

## 6) WOA vs EWOA Comparison (single image)

There’s a utility to compare decisions between EWOA and vanilla WOA:

```bash
python3 -m woa_tool.compare_predict \
  --image data/test_images/1-002.jpg \
  --ewoa models/model_ewoa.json \
  --woa models/model_woa.json \
  --csv data/test.csv

```

Prints a clean JSON like:

```json
{
{
  "Image": "data/test_images/1-002.jpg",
  "Ground Truth": "Malignant",
  "EWOA": {
    "Prediction": "Malignant",
    "Correct": true,
    "Outcome": "TP",
    "Confidence": 1.008,
    "Distance Ratio": 0.9922,
    "Tau Used": 1.0014,
    "Top Features": [
      "glcm_sum_avg",
      "glcm_entropy",
      "hist_mean",
      "shape_norm_area",
      "shape_circularity"
    ],
    "Execution Time": 1.776
  },
  "WOA": {
    "Prediction": "Benign",
    "Correct": false,
    "Outcome": "FN",
    "Confidence": 1.0,
    "Distance Ratio": 1.0,
    "Tau Used": 1.0,
    "Top Features": [
      "spic_edge_ring_ratio",
      "glcm_IDM",
      "glcm_sum_avg",
      "density_index",
      "hist_mean"
    ],
    "Execution Time": 3.64
  },
  "Correct Classification": "Malignant"
}

}
```

> Internals: both paths use the same feature extractor; the comparison code computes a simple ratio `(d_M+eps)/(d_B+eps)` with a diagonal pooled covariance for parity.

---

## 7) Frontend Integration (API sketch)

Expose a thin HTTP layer around the CLI/predict function. Example **FastAPI** snippet:

```python
# app.py
from fastapi import FastAPI, UploadFile, File
from woa_tool.predict import predict
import tempfile, shutil

MODEL_PATH = "models/model_ewoa.json"

app = FastAPI()

@app.post("/predict")
async def predict_endpoint(file: UploadFile = File(...)):
    with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp:
        shutil.copyfileobj(file.file, tmp)
        tmp.flush()
        res = predict(MODEL_PATH, tmp.name)  # or tau_override=...
    return res
```

Run:

```bash
uvicorn app:app --reload --port 8000
```

Frontend can POST an image and render the returned JSON (final label, explanations, abnormality type, top features, etc.).

---

## 8) Reproducibility & Performance

* **Seeds:** `RANDOM_SEED = 42` is set for Numpy + Python `random`. EWOA is still stochastic; expect minor variation across runs.
* **FAST modes:** iterate with `FAST=2`, then do a final `FAST=0` run for best results.
* **Caching:** feature JSONs live in `data/cache/features/`; delete if you change feature definitions.
* **Speed:** Using Ledoit-Wolf shrinkage stabilizes covariance and avoids singularities with many features.

---

## 9) Troubleshooting

**`KeyError: 'class_stats'` in predict**
You’re probably using an older/newer model JSON with a different schema. This repo’s `predict.py` expects:

```json
"class_stats": {"0":{"mu":[...]}, "1":{"mu":[...]}}
"Sp_inv": [[...]], "train_mu": [...], "train_sigma": [...], "tau": ...
```

Re-train with `train_and_eval.py`, or adjust your `predict.py` to match the saved keys.

**`TEST_CSV must contain 'image_path'`**
Make sure `data/test.csv` exists and has the exact `image_path` column.

**Sonar rule (variable name like `zB`)**
We use `zB`/`zM` for clarity. If your linter forbids uppercase, rename to `zb`, `zm` (functional no-op).

**Preprocess taking long**
It’s normal on first run; subsequent runs reuse `data/cache/features`.

---

## 10) Design Notes

* **Classifier:** Mahalanobis ratio with shared pooled covariance in the **selected** feature space.
* **Feature selection:** EWOA with optional Opposition-Based Learning and adaptive `a` schedule.
* **τ policy:** recall-leaning but with specificity guardrails (`MIN_SPECIFICITY`, `FALLBACK_SPEC_FLOOR`). Dense local refinement around best & CV seeds.
* **Artifacts:** CSV dumps for sweep and summary enable plotting/reporting.

---

## 11) Handy Commands (Copy/Paste)

```bash
# Clean caches (if you change feature extraction)
rm -rf data/cache/features

# Preprocess
python3 -m woa_tool.cli preprocess

# Train (balanced-speed)
FAST=2 python3 train_and_eval.py

# Train (full)
FAST=0 python3 train_and_eval.py

# Predict (default τ)
python3 -m woa_tool.cli predict --model models/model_ewoa.json --image data/test_images/1-002.jpg

# Predict (override τ)
python3 -m woa_tool.cli predict --model models/model_ewoa.json --image data/test_images/1-002.jpg --tau-override 1.0014

# Persist τ into model
python3 -m woa_tool.cli set-tau --model models/model_ewoa.json --tau 1.0014

# Compare EWOA vs WOA on one image
python3 compare_woa_ewoa.py \
  --image data/test_images/1-002.jpg \
  --ewoa models/model_ewoa.json \
  --woa  models/model_woa.json
```

